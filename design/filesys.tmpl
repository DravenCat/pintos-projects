       	     +-------------------------+
             | CSCC69                  |
             | PROJECT 4: FILE SYSTEMS |
             | DESIGN DOCUMENT         |
             +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Jiayu Lu <jiay.lu@mail.utoronto.ca>
Dezhi Ren <dezhi.ren@mail.utoronto.ca>
Mengqi Zhao <hart.zhao@mail.utoronto.ca>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

             INDEXED AND EXTENSIBLE FILES
             ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct inode_disk
{
  off_t length;                 /* File size in bytes. */
  uint32_t blocks[BLOCK_NUM];   /* Blocks to store data */
  unsigned isDir;               /* Is directory or not */
  unsigned magic;               /* Magic number. */
  uint32_t unused[110];          /* Not used. */
};

struct inode
{
  struct list_elem elem;  /* Element in inode list. */
  block_sector_t sector;  /* Sector number of disk location. */
  int open_cnt;           /* Number of openers. */
  bool removed;           /* True if deleted, false otherwise. */
  int deny_write_cnt;     /* 0: writes ok, >0: deny writes. */
  struct inode_disk data; /* Inode content. */
  struct lock lock;       /* For synchronization */
};

struct data_index
{
  uint32_t secondary_index[LEVEL_NUM];  /* An array of secondary Index for locating data.  */
  uint32_t primary_index[LEVEL_NUM];    /* An array of primary Index for locating data.  */
  uint16_t lev;                         /* The block level where the offset is*/
  uint32_t off;                         /* Data Offset */
};

// the number of blocks for each level
#define BLOCK_NUM 15
#define DIRECT_BLOCK_NUM 12
#define INDIRECT_BLOCK_NUM 1
#define DOUBLE_INDIRECT_BLOCK_NUM 1
#define TRIPLE_INDIRECT_BLOCK_NUM 1

// the number of bytes for each level of blocks
#define LEVEL0_INDEX (DIRECT_BLOCK_NUM * BLOCK_SECTOR_SIZE)
#define LEVEL1_INDEX (LEVEL0_INDEX + INDIRECT_PTRS * BLOCK_SECTOR_SIZE)
#define LEVEL2_INDEX (LEVEL1_INDEX + INDIRECT_PTRS * INDIRECT_PTRS * BLOCK_SECTOR_SIZE)
#define LEVEL3_INDEX (LEVEL2_INDEX + INDIRECT_PTRS * INDIRECT_PTRS * INDIRECT_PTRS * BLOCK_SECTOR_SIZE)

>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.

We have 12 direct block, 1 indirect block, 1 double indirect block and 1 triple indirect block.
For size of 12 direct block: 12 * 512 bytes
For size of 1 indirect block: 128 * 512 bytes
For size of 1 double indirect block: 128 * 128 * 512 bytes
For size of 1 triple indirect block: 128 * 128 * 128 * 512 bytes
So the maximum size is the total size of all blocks: 1082202112 bytes

---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.

A lock is initialized for every inode when it is opened. If a process attempt to write
to a file, it must acquire the lock of that inode. Therefore, the second process must wait for 
the first one to finish writing until it can write.

>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.

A cannot read anything until the inode length is incremented.
The inode length only get incremented after B finishes writing.
A is able to read the nonzero data that B writes after B finishes writing.
A will see nothing before B finishes writing.

>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.

Our design ensures the fairness for file access. We use the lock struct to implement
the synchronization. For every file access, processes need to acquire a lock.
Every process have the equal chance to successfully acquire the inode lock, so it is
unlikely that these situation will happen

---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?

Our inode structure is a multilevel index. We choose this particular combination because
it allows the files in the system to extend to a large amount of size. The 12 direct blocks, 1
indirect block and 1 double indirect block we choose in this design is able to store the small or
medium size files in the system. We also implement a triple indirect block which can store 128 times the size
of double indirect block to deal with large file in the system. The number of different kinds of block level can
also be easily modified in our design.

                SUBDIRECTORIES
                ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread
{
    char* pwd;
    struct dir *cwd;
}

---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

For the absolute path, we just use strtok_r to retreive each directory name by the 
delimiter '/'. Each time we get a directory/file name from strtok_r, we use dir lookup to 
check whether it exists in its parent directory and then go into it/return it. For relative
path, if we already have the current working directory recorded, we will just use relative
path and do the lookup step. If not, we will use get_full_path to change it into absolute 
path. Then do the traversal algorithm as usual.

---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

We simply implement a lock for action on directory. Just like writing files,
one user must wait for any other user until others finish making new directory
or removing existing directory. Since the original Pintos system has already
disable a single directory to contains two files/directories with the same name
we successfully prevent the races.

>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

No. Just like files, if the directory is opened, it cannot be removed until
it is closed by its opener. We use open count to record how many times a directory
is opened. We using path check to check if the directory is the current working directory
or a parent directory. If it pass the path check, then we will check whether the directory
is opened. Only directories pass these two check can be removed.

---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

We maintain two parameters in thread struct. The cwd is a dir struct that store
the pointer to the current working directory. The pwd is a string that store the
absolute path of the current working directory. The reason we use these two parameters
at the same time is that some checks for open/remove/make is handled by string format while
getting the current directory is more convenient through a pointer. We think this save some 
CPU usage.

                 BUFFER CACHE
                 ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct buffer_cache_entry {

    char data[BLOCK_SECTOR_SIZE];                          // the data in 512 bytes

    block_sector_t sec_num;                                // the corresponding sector number of the inode

    int lru;                                               // the number to evict blocks using LRU
    bool used;                                             // if the block is in use
    bool dirty;                                            // if the block is dirty

};

struct read_ahead_entry {

    block_sector_t sec_num;                                // the sector index of sector being read ahead
    bool read;                                             // if the sector is already read to buffer cache

};

struct lock buffer_cache_lock;                             // the lock for the sycchronization of buffer cache
struct buffer_cache_entry cache_block_arr[CACHE_SIZE];     // the array for buffer cache
struct read_ahead_entry read_ahead_arr[CACHE_SIZE];        // the array for read ahead

---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

We use LRU to decide which block to evict. The struct member lru is a int 
that keeps track of the least recently used block. Everytime a read_cache or
write_cache happens, increment the lru for all used sector of the buffer cache
by 1, and set the lru of current read sector or write sector to 0, which is the
most recently used. When the buffer cache is full, evict the sector with the
greatest lru.

>> C3: Describe your implementation of write-behind.

During the initialization of buffer cache, we thread_create a background
asynchronous thread that periodically write back the dirty buffer cache
blocks by calling timer_sleep in a non-stop while loop.

>> C4: Describe your implementation of read-ahead.

During the initialization of buffer cache, we also thread_create a background
asynchronous thread that periodically traverse the read_ahead_arr to check if
there is any new ahead blocks to read by calling timer_sleep in a non-stop
while loop.

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?

We implemented a lock for buffer cache to help with the synchronization when
a process is reading or writing data in a buffer cache block so that other
processes have to wait until that process finishes the reading or writing 
and releases the lock.

>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

The eviction happens during the process of read_cache and write_cache.
Again, the buffer cache lock will be released when the reading or writing
have finished, which is after the eviction. Until then, other processes
are prevented from accessing the block.

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

Workload that requires reading and writing in the same sector multiple
times will benefit from buffer caching since except for the first time,
IO operation will be no longer needed.

Workload that requires reading from consecutive sectors will benefit from
read ahead since except for the reading from the first sector of the consecutive 
sectors, there will be no IO operation needed for the subsequent sectors.

Workload that requires writing to the same sector multiple times in a short
period will benefit from write behind since less IO operation will be needed
based on how long the time window is between each write back to the disk.



               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?
